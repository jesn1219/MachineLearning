{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writer : JESOON KANG, Dept. of Computer Science & Engineering in Chung-Ang University\n",
    "# Last-Modified Date : April 30,2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2060 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "### Setting up Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Below codes activates when want to use cpu\n",
    "#device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data    = np.genfromtxt(\"data-nonlinear.txt\", delimiter=',')\n",
    "\n",
    "x       = data[:, 0]\n",
    "y       = data[:, 1]\n",
    "label   = data[:, 2]\n",
    "\n",
    "x_label0    = x[label == 0]\n",
    "y_label0    = y[label == 0]\n",
    "\n",
    "x_label1    = x[label == 1]\n",
    "y_label1    = y[label == 1]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x_label0, y_label0, alpha=0.9, c='b')\n",
    "plt.scatter(x_label1, y_label1, alpha=0.9, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.DoubleTensor(x).to('cuda')\n",
    "y = torch.DoubleTensor(y).to('cuda')\n",
    "label = torch.DoubleTensor(label).to('cuda')\n",
    "x = x.unsqueeze(1)\n",
    "y = y.unsqueeze(1)\n",
    "label = label.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph (thetas) :\n",
    "    thetas_len = len(thetas)\n",
    "    \n",
    "    mesh_x = torch.linspace(-2,2,256,dtype=torch.double).to('cuda')\n",
    "    mesh_y = torch.linspace(-2,2,256,dtype=torch.double).to('cuda')\n",
    "    XX, YY = torch.meshgrid(mesh_x,mesh_y)\n",
    "    if thetas_len == 10 :\n",
    "        ZZ = get_function_3(XX,YY)\n",
    "    elif thetas_len == 16 :\n",
    "        ZZ = get_function_4(XX,YY)\n",
    "\n",
    "    ZZ = torch.reshape(ZZ,(thetas_len,65536))\n",
    "    ZZ = torch.matmul(thetas.T,ZZ)\n",
    "    ZZ = torch.reshape(ZZ,(256,256))\n",
    "    yh = 1 / (1 + torch.exp(-ZZ))\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(x_label0, y_label0, alpha=0.9, c='b')\n",
    "    plt.scatter(x_label1, y_label1, alpha=0.9, c='r')\n",
    "    plt.contour(XX.cpu(), YY.cpu(), yh.cpu(), levels= [0.5])\n",
    "    plt.show()\n",
    "    \n",
    "def get_running_time(start_time) :\n",
    "    running_time = datetime.datetime.now() - start_time\n",
    "    running_time = running_time.seconds\n",
    "    hours, remainder = divmod(running_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return hours, minutes, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_4(x,y) :\n",
    "    constant = torch.ones(x.shape,dtype=torch.float64).to('cuda')\n",
    "    ret = torch.stack((constant,x,y,\\\n",
    "                       x*y,x**2,y**2,\\\n",
    "                       x**2*y, x*y**2,x**3,y**3,\\\n",
    "                       x**3*y, x*y**3,\\\n",
    "                       x**3*y**2,x**2*y**3,\\\n",
    "                       x**3*y**3,x**5*y**5\\\n",
    "                      ))\n",
    "    ret = ret.squeeze(-1)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr : 0.001, epoch 10000,loss 0.8145908039, acc 0.407, time : 00:01:18\n",
      "lr : 0.001, epoch 20000,loss 0.7118585704, acc 0.449, time : 00:02:32\n",
      "lr : 0.001, epoch 30000,loss 0.6652610190, acc 0.593, time : 00:03:44\n",
      "lr : 0.001, epoch 40000,loss 0.6352119823, acc 0.644, time : 00:04:56\n",
      "lr : 0.001, epoch 50000,loss 0.6114446462, acc 0.703, time : 00:06:08\n",
      "lr : 0.001, epoch 60000,loss 0.5910981492, acc 0.737, time : 00:07:20\n",
      "lr : 0.001, epoch 70000,loss 0.5732099229, acc 0.754, time : 00:08:32\n",
      "lr : 0.001, epoch 80000,loss 0.5573166594, acc 0.771, time : 00:09:44\n",
      "lr : 0.001, epoch 90000,loss 0.5431108454, acc 0.797, time : 00:10:56\n",
      "lr : 0.001, epoch 100000,loss 0.5303534749, acc 0.788, time : 00:12:10\n",
      "lr : 0.001, epoch 110000,loss 0.5188482927, acc 0.797, time : 00:13:22\n",
      "lr : 0.001, epoch 120000,loss 0.5084312399, acc 0.805, time : 00:14:34\n",
      "lr : 0.001, epoch 130000,loss 0.4989641615, acc 0.797, time : 00:15:46\n",
      "lr : 0.001, epoch 140000,loss 0.4903301560, acc 0.780, time : 00:16:58\n",
      "lr : 0.001, epoch 150000,loss 0.4824298713, acc 0.797, time : 00:18:09\n",
      "lr : 0.001, epoch 160000,loss 0.4751784999, acc 0.797, time : 00:19:21\n",
      "lr : 0.001, epoch 170000,loss 0.4685033302, acc 0.797, time : 00:20:33\n",
      "lr : 0.001, epoch 180000,loss 0.4623417482, acc 0.797, time : 00:21:45\n",
      "lr : 0.001, epoch 190000,loss 0.4566396041, acc 0.797, time : 00:22:57\n",
      "lr : 0.001, epoch 200000,loss 0.4513498734, acc 0.797, time : 00:24:09\n",
      "lr : 0.001, epoch 210000,loss 0.4464315551, acc 0.797, time : 00:25:21\n",
      "lr : 0.001, epoch 220000,loss 0.4418487625, acc 0.797, time : 00:26:33\n",
      "lr : 0.001, epoch 230000,loss 0.4375699689, acc 0.797, time : 00:27:45\n",
      "lr : 0.001, epoch 240000,loss 0.4335673797, acc 0.805, time : 00:28:56\n",
      "lr : 0.001, epoch 250000,loss 0.4298164079, acc 0.805, time : 00:30:09\n",
      "lr : 0.001, epoch 260000,loss 0.4262952328, acc 0.805, time : 00:31:20\n",
      "lr : 0.001, epoch 270000,loss 0.4229844293, acc 0.805, time : 00:32:32\n",
      "lr : 0.001, epoch 280000,loss 0.4198666531, acc 0.805, time : 00:33:44\n",
      "lr : 0.001, epoch 290000,loss 0.4169263743, acc 0.805, time : 00:34:56\n",
      "lr : 0.001, epoch 300000,loss 0.4141496496, acc 0.805, time : 00:36:08\n",
      "lr : 0.001, epoch 310000,loss 0.4115239276, acc 0.805, time : 00:37:20\n",
      "lr : 0.001, epoch 320000,loss 0.4090378819, acc 0.805, time : 00:38:32\n",
      "lr : 0.001, epoch 330000,loss 0.4066812671, acc 0.805, time : 00:39:44\n",
      "lr : 0.001, epoch 340000,loss 0.4044447945, acc 0.805, time : 00:40:56\n",
      "lr : 0.001, epoch 350000,loss 0.4023200242, acc 0.805, time : 00:42:09\n",
      "lr : 0.001, epoch 360000,loss 0.4002992718, acc 0.805, time : 00:43:21\n",
      "lr : 0.001, epoch 370000,loss 0.3983755260, acc 0.805, time : 00:44:33\n",
      "lr : 0.001, epoch 380000,loss 0.3965423781, acc 0.805, time : 00:45:45\n",
      "lr : 0.001, epoch 390000,loss 0.3947939587, acc 0.805, time : 00:46:57\n",
      "lr : 0.001, epoch 400000,loss 0.3931248829, acc 0.805, time : 00:48:09\n",
      "lr : 0.001, epoch 410000,loss 0.3915302020, acc 0.805, time : 00:49:19\n",
      "lr : 0.001, epoch 420000,loss 0.3900053605, acc 0.805, time : 00:50:26\n",
      "lr : 0.001, epoch 430000,loss 0.3885461583, acc 0.805, time : 00:51:33\n",
      "lr : 0.001, epoch 440000,loss 0.3871487168, acc 0.805, time : 00:52:41\n",
      "lr : 0.001, epoch 450000,loss 0.3858094495, acc 0.805, time : 00:53:48\n",
      "lr : 0.001, epoch 460000,loss 0.3845250348, acc 0.814, time : 00:54:56\n",
      "lr : 0.001, epoch 470000,loss 0.3832923927, acc 0.822, time : 00:56:02\n",
      "lr : 0.001, epoch 480000,loss 0.3821086629, acc 0.822, time : 00:57:09\n",
      "lr : 0.001, epoch 490000,loss 0.3809711863, acc 0.822, time : 00:58:17\n",
      "lr : 0.001, epoch 500000,loss 0.3798774874, acc 0.822, time : 00:59:24\n",
      "lr : 0.001, epoch 510000,loss 0.3788252593, acc 0.831, time : 01:00:32\n",
      "lr : 0.001, epoch 520000,loss 0.3778123493, acc 0.831, time : 01:01:38\n",
      "lr : 0.001, epoch 530000,loss 0.3768367467, acc 0.831, time : 01:02:45\n",
      "lr : 0.001, epoch 540000,loss 0.3758965712, acc 0.831, time : 01:03:52\n",
      "lr : 0.001, epoch 550000,loss 0.3749900627, acc 0.831, time : 01:04:59\n",
      "lr : 0.001, epoch 560000,loss 0.3741155722, acc 0.831, time : 01:06:06\n",
      "lr : 0.001, epoch 570000,loss 0.3732715527, acc 0.831, time : 01:07:13\n",
      "lr : 0.001, epoch 580000,loss 0.3724565522, acc 0.831, time : 01:08:20\n",
      "lr : 0.001, epoch 590000,loss 0.3716692060, acc 0.831, time : 01:09:27\n",
      "lr : 0.001, epoch 600000,loss 0.3709082310, acc 0.831, time : 01:10:34\n",
      "lr : 0.001, epoch 610000,loss 0.3701724190, acc 0.831, time : 01:11:40\n",
      "lr : 0.001, epoch 620000,loss 0.3694606320, acc 0.831, time : 01:12:48\n",
      "lr : 0.001, epoch 630000,loss 0.3687717970, acc 0.831, time : 01:13:55\n",
      "lr : 0.001, epoch 640000,loss 0.3681049014, acc 0.831, time : 01:15:02\n",
      "lr : 0.001, epoch 650000,loss 0.3674589890, acc 0.831, time : 01:16:08\n",
      "lr : 0.001, epoch 660000,loss 0.3668331563, acc 0.831, time : 01:17:16\n",
      "lr : 0.001, epoch 670000,loss 0.3662265487, acc 0.831, time : 01:18:23\n",
      "lr : 0.001, epoch 680000,loss 0.3656383576, acc 0.831, time : 01:19:29\n",
      "lr : 0.001, epoch 690000,loss 0.3650678169, acc 0.839, time : 01:20:36\n",
      "lr : 0.001, epoch 700000,loss 0.3645142010, acc 0.839, time : 01:21:44\n",
      "lr : 0.001, epoch 710000,loss 0.3639768216, acc 0.839, time : 01:22:51\n",
      "lr : 0.001, epoch 720000,loss 0.3634550255, acc 0.839, time : 01:23:58\n",
      "lr : 0.001, epoch 730000,loss 0.3629481927, acc 0.839, time : 01:25:04\n",
      "lr : 0.001, epoch 740000,loss 0.3624557342, acc 0.839, time : 01:26:12\n",
      "lr : 0.001, epoch 750000,loss 0.3619770900, acc 0.839, time : 01:27:18\n",
      "lr : 0.001, epoch 760000,loss 0.3615117274, acc 0.839, time : 01:28:25\n",
      "lr : 0.001, epoch 770000,loss 0.3610591395, acc 0.847, time : 01:29:32\n",
      "lr : 0.001, epoch 780000,loss 0.3606188438, acc 0.847, time : 01:30:40\n",
      "lr : 0.001, epoch 790000,loss 0.3601903804, acc 0.847, time : 01:31:47\n",
      "lr : 0.001, epoch 800000,loss 0.3597733111, acc 0.847, time : 01:32:54\n",
      "lr : 0.001, epoch 810000,loss 0.3593672179, acc 0.847, time : 01:34:01\n",
      "lr : 0.001, epoch 820000,loss 0.3589717019, acc 0.847, time : 01:35:08\n",
      "lr : 0.001, epoch 830000,loss 0.3585863825, acc 0.847, time : 01:36:15\n",
      "lr : 0.001, epoch 840000,loss 0.3582108962, acc 0.847, time : 01:37:22\n",
      "lr : 0.001, epoch 850000,loss 0.3578448954, acc 0.847, time : 01:38:28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setting Step-size. (Learning-rate)\n",
    "lr = 1e-3\n",
    "lr = torch.DoubleTensor([lr]).to('cuda')\n",
    "\n",
    "# Setting converge value\n",
    "loss_conv = 5e-9 # loss converge standard\n",
    "\n",
    "# Lists for logging\n",
    "loss_log = []\n",
    "epoch_log = []\n",
    "acc_log = []\n",
    "conv_count = 0 # Variable To count converge\n",
    "epoch = 0 # Inital epoch value\n",
    "\n",
    "thetas = torch.ones((16,1),dtype=torch.float64).to('cuda') \n",
    "fx = get_function_4(x,y)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "while (True) :\n",
    "    epoch +=1\n",
    "    epoch_log.append(epoch)\n",
    "    z = torch.matmul(thetas.T,fx)\n",
    "    z = z.T\n",
    "    activ_values = 1 / (1+torch.exp(-z))\n",
    "    m = len(activ_values)\n",
    "    \n",
    "    # Get Loss \n",
    "    loss = (1/m) * torch.sum( \\\n",
    "                             -label*torch.log(activ_values) - (1-label)*torch.log(1 - activ_values))\n",
    "    \n",
    "    # Updating Parameters - Gradient Descent\n",
    "    thetas[0] -= lr * (1/m) * torch.sum(activ_values-label)\n",
    "    thetas[1] -= lr * (1/m) * torch.sum( (activ_values-label)* x)\n",
    "    thetas[2] -= lr * (1/m) * torch.sum( (activ_values-label)* y)\n",
    "    thetas[3] -= lr * (1/m) * torch.sum( (activ_values-label)* x*y)\n",
    "    thetas[4] -= lr * (1/m) * torch.sum( (activ_values-label)* x**2)\n",
    "    thetas[5] -= lr * (1/m) * torch.sum( (activ_values-label)* y**2)\n",
    "    thetas[6] -= lr * (1/m) * torch.sum( (activ_values-label)* x**2*y)\n",
    "    thetas[7] -= lr * (1/m) * torch.sum( (activ_values-label)* x*y**2)\n",
    "    thetas[8] -= lr * (1/m) * torch.sum( (activ_values-label)* x**3)\n",
    "    thetas[9] -= lr * (1/m) * torch.sum( (activ_values-label)* y**3)\n",
    "    thetas[10] -= lr * (1/m) * torch.sum( (activ_values-label)* x**3*y)\n",
    "    thetas[11] -= lr * (1/m) * torch.sum( (activ_values-label)* x*y**3)\n",
    "    thetas[12] -= lr * (1/m) * torch.sum( (activ_values-label)* x**3*y**2)\n",
    "    thetas[13] -= lr * (1/m) * torch.sum( (activ_values-label)* x**2*y**3)\n",
    "    thetas[14] -= lr * (1/m) * torch.sum( (activ_values-label)* x**3*y**3)\n",
    "    thetas[15] -= lr * (1/m) * torch.sum( (activ_values-label)* y**5*y**5)\n",
    "    \n",
    "    # Logging\n",
    "    loss_log.append(loss)\n",
    "\n",
    "    ## Does Train Loss Converged?\n",
    "    if len(loss_log) > 2 :\n",
    "        if abs(loss_log[-1] - loss_log[-2]) < loss_conv :\n",
    "            conv_count += 1\n",
    "        else :\n",
    "            conv_count = 0\n",
    "    \n",
    "    # calculate Accuracy        \n",
    "    acc = 0\n",
    "    for i in range(0,len(activ_values)) :\n",
    "        if activ_values[i] >= 0.5 :\n",
    "            if label[i] == 1 :\n",
    "                acc += 1\n",
    "        else :\n",
    "            if label[i] == 0 :\n",
    "                acc += 1\n",
    "    acc = acc / len(activ_values)\n",
    "    acc_log.append(acc)\n",
    "\n",
    "    \n",
    "    # For monitoring\n",
    "    if epoch %10000 == 0 :        \n",
    "        running_time = get_running_time(start_time)\n",
    "        print(\"lr : {}, epoch {},loss {:.10f}, acc {:.3f}, time : {:02d}:{:02d}:{:02d}\".\\\n",
    "              format(lr.item(), epoch,loss_log[-1],acc_log[-1],running_time[0],running_time[1],running_time[2]) )\n",
    "        #show_graph(thetas)\n",
    "    ## Escape if Training loss is converged\n",
    "    if conv_count > 4 :\n",
    "\n",
    "        print(\"Loss is converged\")\n",
    "        print(\"#\"*30)\n",
    "        running_time = get_running_time(start_time)\n",
    "\n",
    "        print(\"lr : {}, epoch {},loss {:.10f}, acc {:.3f}, time : {:02d}:{:02d}:{:02d}\".\\\n",
    "              format(lr.item(), epoch,loss_log[-1],acc_log[-1],running_time[0],running_time[1],running_time[2]) )               \n",
    "        print(\"#\"*30)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Plot the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x_label0, y_label0, alpha=0.9, c='b')\n",
    "plt.scatter(x_label1, y_label1, alpha=0.9, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write down the high dimensional function $g(x, y); \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\Large\n",
    "  g(x, y ; \\theta) =\n",
    "  1\\times \n",
    "  f_{0}(x, y)\n",
    "  + x f_{1}(x, y)\n",
    "  + y f_{2}(x, y)\n",
    "  \\\\ \\Large\n",
    "  + xy f_{3}(x, y)\n",
    "  + x^{2} f_{4}(x, y)\n",
    "  + y^{2} f_{5}(x, y)\n",
    "  + x^{2}y f_{6}(x, y)\n",
    "  \\\\ \\Large\n",
    "  + xy^{2} f_{7}(x, y)\n",
    "  + x^{3} f_{8}(x, y)\n",
    "  + y^{3} f_{9}(x, y)\n",
    "  + x^{3}y f_{10}(x, y)\n",
    "  \\\\ \\Large\n",
    "  + xy^{3} f_{11}(x, y)\n",
    "  + x^{3}y^{2} f_{12}(x, y)\n",
    "  + x^{2}y^{3} f_{13}(x, y)\n",
    "  + x^{3}y^{3} f_{14}(x, y)\n",
    "  + x^{5}y^{5} f_{15}(x, y)\n",
    "}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Plot the training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Training error\")\n",
    "plot, = plt.plot(epoch_log,loss_log, color='blue',linewidth=2,alpha=0.8)\n",
    "plt.legend([plot],[\"Trainging error\"])\n",
    "print(\"Converged Training loss : {:.5f}\".format(loss_log[-1].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plot the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Training Accuracy\")\n",
    "plot, = plt.plot(epoch_log,acc_log, color='blue',linewidth=2,alpha=0.8)\n",
    "plt.legend([plot],[\"Trainging error\"])\n",
    "print(\"Converged Training Accuracy : {:.5f}\".format(acc_log[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Write down the final training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final training accuracy : 85.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Plot the optimal classifier superimposed on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thetas_4 = thetas\n",
    "show_graph(thetas_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
